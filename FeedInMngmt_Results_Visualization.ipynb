{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load relevant Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the most important modules\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Results for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To assure that the result data is saved in the right format and directory to be visualized 2 dataframes are set up:\n",
    "- The first one will include all the predictions for each model for both the validation and the test set and for each timestep.\n",
    "- The second one will include all the actual observed values for each model for both the validation and the test set and for each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Step 1</th>\n",
       "      <th>Step 2</th>\n",
       "      <th>Step 3</th>\n",
       "      <th>Step 4</th>\n",
       "      <th>Step 5</th>\n",
       "      <th>Step 6</th>\n",
       "      <th>Step 7</th>\n",
       "      <th>Step 8</th>\n",
       "      <th>Step 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Step 11</th>\n",
       "      <th>Step 12</th>\n",
       "      <th>Step 13</th>\n",
       "      <th>Step 14</th>\n",
       "      <th>Step 15</th>\n",
       "      <th>Step 16</th>\n",
       "      <th>Step 17</th>\n",
       "      <th>Step 18</th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-17 06:00:00</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>Naive Shift Model</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-17 06:10:00</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>Naive Shift Model</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date    Step 1    Step 2    Step 3    Step 4    Step 5  \\\n",
       "0  2019-03-17 06:00:00  0.327166  0.327166  0.327166  0.327166  0.327166   \n",
       "1  2019-03-17 06:10:00  0.453624  0.453624  0.453624  0.453624  0.453624   \n",
       "\n",
       "     Step 6    Step 7    Step 8    Step 9  ...   Step 11   Step 12   Step 13  \\\n",
       "0  0.327166  0.327166  0.327166  0.327166  ...  0.327166  0.327166  0.327166   \n",
       "1  0.453624  0.453624  0.453624  0.453624  ...  0.453624  0.453624  0.453624   \n",
       "\n",
       "    Step 14   Step 15   Step 16   Step 17   Step 18              Model  \\\n",
       "0  0.327166  0.327166  0.327166  0.327166  0.327166  Naive Shift Model   \n",
       "1  0.453624  0.453624  0.453624  0.453624  0.453624  Naive Shift Model   \n",
       "\n",
       "      Dataset  \n",
       "0  Validation  \n",
       "1  Validation  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnnames = [\"date\",\"Step 1\",\"Step 2\",\"Step 3\",\"Step 4\",\"Step 5\",\"Step 6\",\"Step 7\",\"Step 8\",\"Step 9\",\n",
    "               \"Step 10\",\"Step 11\",\"Step 12\",\"Step 13\",\"Step 14\",\"Step 15\",\"Step 16\",\"Step 17\",\n",
    "               \"Step 18\", \"Model\", \"Dataset\"]\n",
    "\n",
    "# setting up source_pred\n",
    "df_pred = pd.read_csv(\"./Results/naive_shift_validation_predictions.csv\")\n",
    "df_naive_test_pred = pd.read_csv(\"./Results/naive_shift_test_predictions.csv\")\n",
    "df_mov_av_val_pred = pd.read_csv(\"./Results/moving_average_validation_predictions.csv\")\n",
    "df_mov_av_test_pred = pd.read_csv(\"./Results/moving_average_test_predictions.csv\")\n",
    "df_prophet_val_pred = pd.read_csv(\"./Results/prophet_validation_predictions.csv\")\n",
    "df_prophet_test_pred = pd.read_csv(\"./Results/prophet_test_predictions.csv\")\n",
    "df_multi_lstm_peephole_val_pred = pd.read_csv(\"./Results/multi_lstm_peephole_validation_predictions.csv\")\n",
    "df_multi_lstm_peephole_test_pred = pd.read_csv(\"./Results/multi_lstm_peephole_test_predictions.csv\")\n",
    "df_uni_lstm_peephole_val_pred = pd.read_csv(\"./Results/uni_lstm_peephole_validation_predictions.csv\")\n",
    "df_uni_lstm_peephole_test_pred = pd.read_csv(\"./Results/uni_lstm_peephole_test_predictions.csv\")\n",
    "df_multi_lstm_val_pred = pd.read_csv(\"./Results/multi_lstm_validation_predictions.csv\")\n",
    "df_multi_lstm_test_pred = pd.read_csv(\"./Results/multi_lstm_test_predictions.csv\")\n",
    "df_uni_lstm_val_pred = pd.read_csv(\"./Results/uni_lstm_validation_predictions.csv\")\n",
    "df_uni_lstm_test_pred = pd.read_csv(\"./Results/uni_lstm_test_predictions.csv\")\n",
    "\n",
    "# assuring coherence between the datasets\n",
    "df_mov_av_val_pred.drop(columns = [\"y_all_pred Step 19\",\"y_all_pred Step 20\"], inplace = True)\n",
    "df_mov_av_test_pred.drop(columns = [\"y_all_pred Step 19\",\"y_all_pred Step 20\"], inplace = True)\n",
    "df_prophet_val_pred.columns = df_pred.columns\n",
    "df_prophet_test_pred.columns = df_pred.columns\n",
    "df_multi_lstm_peephole_val_pred.columns = df_pred.columns\n",
    "df_multi_lstm_peephole_test_pred.columns = df_pred.columns\n",
    "df_uni_lstm_peephole_val_pred.columns = df_pred.columns\n",
    "df_uni_lstm_peephole_test_pred.columns = df_pred.columns\n",
    "df_multi_lstm_val_pred.columns = df_pred.columns\n",
    "df_multi_lstm_test_pred.columns = df_pred.columns\n",
    "df_uni_lstm_val_pred.columns = df_pred.columns\n",
    "df_uni_lstm_test_pred.columns = df_pred.columns\n",
    "df_multi_lstm_peephole_val_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_multi_lstm_peephole_test_pred[\"date\"] = df_naive_test_pred.date.iloc[0:1420]\n",
    "df_uni_lstm_peephole_val_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_uni_lstm_peephole_test_pred[\"date\"] = df_naive_test_pred.date.iloc[0:1420]\n",
    "df_multi_lstm_val_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_multi_lstm_test_pred[\"date\"] = df_naive_test_pred.date.iloc[0:1420]\n",
    "df_uni_lstm_val_pred[\"date\"] = df_pred.date.iloc[0:1420]\n",
    "df_uni_lstm_test_pred[\"date\"] = df_naive_test_pred.date.iloc[0:1420]\n",
    "\n",
    "# creating selectors for dataset variable\n",
    "df_pred[\"Dataset\"] = \"Validation\"\n",
    "df_naive_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_mov_av_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_mov_av_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_prophet_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_prophet_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_multi_lstm_peephole_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_multi_lstm_peephole_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_uni_lstm_peephole_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_uni_lstm_peephole_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_multi_lstm_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_multi_lstm_test_pred[\"Dataset\"] = \"Test\"\n",
    "df_uni_lstm_val_pred[\"Dataset\"] = \"Validation\"\n",
    "df_uni_lstm_test_pred[\"Dataset\"] = \"Test\"\n",
    "\n",
    "\n",
    "# stacking all the predictions from the different models on the validation and test sets in one dataframe\n",
    "df_pred = df_pred.append(df_naive_test_pred,)\n",
    "df_pred = df_pred.append(df_mov_av_val_pred)\n",
    "df_pred = df_pred.append(df_mov_av_test_pred)\n",
    "df_pred = df_pred.append(df_prophet_val_pred)\n",
    "df_pred = df_pred.append(df_prophet_test_pred)\n",
    "df_pred = df_pred.append(df_multi_lstm_peephole_val_pred)\n",
    "df_pred = df_pred.append(df_multi_lstm_peephole_test_pred)\n",
    "df_pred = df_pred.append(df_uni_lstm_peephole_val_pred)\n",
    "df_pred = df_pred.append(df_uni_lstm_peephole_test_pred)\n",
    "df_pred = df_pred.append(df_multi_lstm_val_pred)\n",
    "df_pred = df_pred.append(df_multi_lstm_test_pred)\n",
    "df_pred = df_pred.append(df_uni_lstm_val_pred)\n",
    "df_pred = df_pred.append(df_uni_lstm_test_pred)\n",
    "df_pred.columns = columnnames\n",
    "df_pred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Step 1</th>\n",
       "      <th>Step 2</th>\n",
       "      <th>Step 3</th>\n",
       "      <th>Step 4</th>\n",
       "      <th>Step 5</th>\n",
       "      <th>Step 6</th>\n",
       "      <th>Step 7</th>\n",
       "      <th>Step 8</th>\n",
       "      <th>Step 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Step 11</th>\n",
       "      <th>Step 12</th>\n",
       "      <th>Step 13</th>\n",
       "      <th>Step 14</th>\n",
       "      <th>Step 15</th>\n",
       "      <th>Step 16</th>\n",
       "      <th>Step 17</th>\n",
       "      <th>Step 18</th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-17 06:00:00</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>0.472353</td>\n",
       "      <td>0.466946</td>\n",
       "      <td>0.439173</td>\n",
       "      <td>0.286735</td>\n",
       "      <td>0.265595</td>\n",
       "      <td>0.349561</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>0.344043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246061</td>\n",
       "      <td>0.242016</td>\n",
       "      <td>0.254804</td>\n",
       "      <td>0.263315</td>\n",
       "      <td>0.298216</td>\n",
       "      <td>0.323319</td>\n",
       "      <td>0.308209</td>\n",
       "      <td>0.270959</td>\n",
       "      <td>Naive Shift Model</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-17 06:10:00</td>\n",
       "      <td>0.472353</td>\n",
       "      <td>0.466946</td>\n",
       "      <td>0.439173</td>\n",
       "      <td>0.286735</td>\n",
       "      <td>0.265595</td>\n",
       "      <td>0.349561</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>0.344043</td>\n",
       "      <td>0.264401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242016</td>\n",
       "      <td>0.254804</td>\n",
       "      <td>0.263315</td>\n",
       "      <td>0.298216</td>\n",
       "      <td>0.323319</td>\n",
       "      <td>0.308209</td>\n",
       "      <td>0.270959</td>\n",
       "      <td>0.292321</td>\n",
       "      <td>Naive Shift Model</td>\n",
       "      <td>Validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date    Step 1    Step 2    Step 3    Step 4    Step 5  \\\n",
       "0  2019-03-17 06:00:00  0.453624  0.472353  0.466946  0.439173  0.286735   \n",
       "1  2019-03-17 06:10:00  0.472353  0.466946  0.439173  0.286735  0.265595   \n",
       "\n",
       "     Step 6    Step 7    Step 8    Step 9  ...   Step 11   Step 12   Step 13  \\\n",
       "0  0.265595  0.349561  0.339105  0.344043  ...  0.246061  0.242016  0.254804   \n",
       "1  0.349561  0.339105  0.344043  0.264401  ...  0.242016  0.254804  0.263315   \n",
       "\n",
       "    Step 14   Step 15   Step 16   Step 17   Step 18              Model  \\\n",
       "0  0.263315  0.298216  0.323319  0.308209  0.270959  Naive Shift Model   \n",
       "1  0.298216  0.323319  0.308209  0.270959  0.292321  Naive Shift Model   \n",
       "\n",
       "      Dataset  \n",
       "0  Validation  \n",
       "1  Validation  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up source_test\n",
    "df_test = pd.read_csv(\"./Results/naive_shift_validation_values.csv\")\n",
    "df_naive_test_test = pd.read_csv(\"./Results/naive_shift_test_values.csv\")\n",
    "df_mov_av_val_test = pd.read_csv(\"./Results/moving_average_validation_values.csv\")\n",
    "df_mov_av_test_test = pd.read_csv(\"./Results/moving_average_test_values.csv\")\n",
    "df_prophet_val_test = pd.read_csv(\"./Results/prophet_validation_values.csv\")\n",
    "df_prophet_test_test = pd.read_csv(\"./Results/prophet_test_values.csv\")\n",
    "df_multi_lstm_peephole_val_test = pd.read_csv(\"./Results/multi_lstm_peephole_validation_values.csv\")\n",
    "df_multi_lstm_peephole_test_test = pd.read_csv(\"./Results/multi_lstm_peephole_test_values.csv\")\n",
    "df_uni_lstm_peephole_val_test = pd.read_csv(\"./Results/uni_lstm_peephole_validation_values.csv\")\n",
    "df_uni_lstm_peephole_test_test = pd.read_csv(\"./Results/uni_lstm_peephole_test_values.csv\")\n",
    "df_multi_lstm_val_test = pd.read_csv(\"./Results/multi_lstm_validation_values.csv\")\n",
    "df_multi_lstm_test_test = pd.read_csv(\"./Results/multi_lstm_test_values.csv\")\n",
    "df_uni_lstm_val_test = pd.read_csv(\"./Results/uni_lstm_validation_values.csv\")\n",
    "df_uni_lstm_test_test = pd.read_csv(\"./Results/uni_lstm_test_values.csv\")\n",
    "\n",
    "# assuring coherence between the datasets\n",
    "df_mov_av_val_test.drop(columns = [\"y_all_observed Step 1\",\"y_all_observed Step 2\"], inplace = True)\n",
    "df_mov_av_test_test.drop(columns = [\"y_all_observed Step 1\",\"y_all_observed Step 2\"], inplace = True)\n",
    "df_mov_av_val_test.columns = df_test.columns\n",
    "df_mov_av_test_test.columns = df_test.columns\n",
    "df_prophet_val_test.columns = df_test.columns\n",
    "df_prophet_test_test.columns = df_test.columns\n",
    "df_multi_lstm_peephole_val_test.columns = df_test.columns\n",
    "df_multi_lstm_peephole_test_test.columns = df_test.columns\n",
    "df_uni_lstm_peephole_val_test.columns = df_test.columns\n",
    "df_uni_lstm_peephole_test_test.columns = df_test.columns\n",
    "df_multi_lstm_val_test.columns = df_test.columns\n",
    "df_multi_lstm_test_test.columns = df_test.columns\n",
    "df_uni_lstm_val_test.columns = df_test.columns\n",
    "df_uni_lstm_test_test.columns = df_test.columns\n",
    "df_multi_lstm_peephole_val_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_multi_lstm_peephole_test_test[\"date\"] = df_naive_test_test.date.iloc[0:1420]\n",
    "df_uni_lstm_peephole_val_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_uni_lstm_peephole_test_test[\"date\"] = df_naive_test_test.date.iloc[0:1420]\n",
    "df_multi_lstm_val_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_multi_lstm_test_test[\"date\"] = df_naive_test_test.date.iloc[0:1420]\n",
    "df_uni_lstm_val_test[\"date\"] = df_test.date.iloc[0:1420]\n",
    "df_uni_lstm_test_test[\"date\"] = df_naive_test_test.date.iloc[0:1420]\n",
    "\n",
    "# creating selectors for dataset variable\n",
    "df_test[\"Dataset\"] = \"Validation\"\n",
    "df_naive_test_test[\"Dataset\"] = \"Test\"\n",
    "df_mov_av_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_mov_av_test_test[\"Dataset\"] = \"Test\"\n",
    "df_prophet_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_prophet_test_test[\"Dataset\"] = \"Test\"\n",
    "df_multi_lstm_peephole_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_multi_lstm_peephole_test_test[\"Dataset\"] = \"Test\"\n",
    "df_uni_lstm_peephole_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_uni_lstm_peephole_test_test[\"Dataset\"] = \"Test\"\n",
    "df_multi_lstm_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_multi_lstm_test_test[\"Dataset\"] = \"Test\"\n",
    "df_uni_lstm_val_test[\"Dataset\"] = \"Validation\"\n",
    "df_uni_lstm_test_test[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# stacking all the actual values from the different models on the validation and test sets in one dataframe\n",
    "df_test = df_test.append(df_naive_test_test)\n",
    "df_test = df_test.append(df_mov_av_val_test)\n",
    "df_test = df_test.append(df_mov_av_test_test)\n",
    "df_test = df_test.append(df_prophet_val_test)\n",
    "df_test = df_test.append(df_prophet_test_test)\n",
    "df_test = df_test.append(df_multi_lstm_peephole_val_test)\n",
    "df_test = df_test.append(df_multi_lstm_peephole_test_test)\n",
    "df_test = df_test.append(df_uni_lstm_peephole_val_test)\n",
    "df_test = df_test.append(df_uni_lstm_peephole_test_test)\n",
    "df_test = df_test.append(df_multi_lstm_val_test)\n",
    "df_test = df_test.append(df_multi_lstm_test_test)\n",
    "df_test = df_test.append(df_uni_lstm_val_test)\n",
    "df_test = df_test.append(df_uni_lstm_test_test)\n",
    "df_test.columns = columnnames\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the Stacked Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both stacked dataframes are saved and can now be explored interactively via Bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell was last run on: \n",
      "2020-11-26 11:00:59.165249\n"
     ]
    }
   ],
   "source": [
    "df_test.to_csv(\"./Results/values.csv\", index = False)\n",
    "df_pred.to_csv(\"./Results/predictions.csv\", index = False)\n",
    "\n",
    "print('This cell was last run on: ')\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the interactive Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/visualization_predictions_demo.gif\" alt=\"visualization_demo\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the cell below is executed, an interactive plot (as seen above) will open in your default browser. On the right 3 dropdown selectors enable you to choose of which model for which dataset and for which timestep the results should be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! bokeh serve --show visualization.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop the interactive plot the kernel needs to be restarted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
